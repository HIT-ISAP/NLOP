Rank 0
********************************************************
1. HookeJeeves
	alpha = 1
	init_delta = 0.2
	epsilon = 0.001 // stepsize threshold
	coff = 0.5

********************************************************

Rank 1
********************************************************
1.steepest descent:
	min_gradient = 0.01
********************************************************
2.conjuate gradient
	approximation = FR
	min_gradient = 0.01
********************************************************
3.momentum
	min_gradient = 0.01; // Gradient threshold to stop the iterations
    alpha = 0.003; // learning rate
    beta = 0.9; // momentum hyper-parameters
********************************************************
4.nesterov momentum
	min_gradient = 0.01; // Gradient threshold to stop the iterations
    alpha = 0.001; // learning rate
    beta = 0.9; // momentum hyper-parameters
********************************************************
5.Adagrad
	min_gradient = 0.01; // Gradient threshold to stop the iterations
    alpha = 0.1; // learning rate
    epsilon = 1e-8; // Prevent division by 0
********************************************************
6.AdaDelta
	min_gradient = 0.01; // Gradient threshold to stop the iterations
    alpha = 0.01; // learning rate
    gamma = 0.9; // decay rate
    epsilon = 1e-8; // Prevent division by 0

	1000 steepest descent iterations, then AdaDelta
********************************************************
7.Adam
	min_gradient = 0.01; // Gradient threshold to stop the iterations
    alpha = 0.01; // learning rate
    gamma_v = 0.9; // decay rate v
    gamma_s = 0.999; // decay rate s
    epsilon = 1e-8; // Prevent division by 0
********************************************************
8.RMSProp
	min_gradient = 0.01; // Gradient threshold to stop the iterations
    alpha = 0.001; // learning rate
    gamma = 0.9; // decay rate
    epsilon = 1e-8; // Prevent division by 0
********************************************************

Rank 2
********************************************************
1.Newton
	min_delta_x = 0.01; // stepsize threshold to stop the iterations
********************************************************
2.L-M
	if (R < 0)
      ;
    else if (R < 0.25)
      epsilon *= 4;
    else if (R > 0.75)
      epsilon *= 0.5;

	min_delta_x = 0.0001; // Gradient threshold to stop the iterations
    init_epsilon = 4;
********************************************************
